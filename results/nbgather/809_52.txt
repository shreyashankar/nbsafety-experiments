X_b = np.c_[np.ones((100, 1)), X]  # add x0 = 1 to each instance theta_best = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)
np.ones((5,), dtype=int)
np.ones((1,5), dtype=int)
np.ones((5,), dtype=int)
np.ones((5,), dtype=int)
np.ones((5,1), dtype=int)
np.ones((1,5), dtype=int)
np.ones((5,1), dtype=int)
np.ones((5,), dtype=int)
np.ones((5), dtype=int)
np.ones((1,5), dtype=int)
np.ones((5,1), dtype=int)
np.ones((5,), dtype=int)
X_new = np.array([[0], [2]])
plt.plot(X_new, y_predict, "r")
plt.plot(X_new, y_predict, "r-")
plt.plot(X_new, y_predict, "r-")
plt.plot(X_new, y_predict, "r-")
plt.plot(X_new, y_predict, "r-")
plt.plot(X, y, "b.")
plt.plot(X_new, y_predict, "r-")
plt.plot(X, y, "b.")
plt.plot(X_new, y_predict, )
plt.plot(X, y, "b")
plt.plot(X, y, "b-")
plt.plot(X, y, )
plt.plot(X, y,"." )
plt.plot(X_new, y_predict, "r-")
plt.plot(X, y,"." )
plt.axis([0, 2, 0, 15]) 
train_errors, val_errors = [], []
def plot_learning_curves(model, X, y):
    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)
    train_errors, val_errors = [], []
    for m in range(1, len(X_train)):        
        model.fit(X_train[:m], y_train[:m])
        y_train_predict = model.predict(X_train[:m])
        y_val_predict = model.predict(X_val)
        train_errors.append(mean_squared_error(y_train[:m], y_train_predict))
        val_errors.append(mean_squared_error(y_val, y_val_predict))
from sklearn.pipeline import Pipeline
polynomial_regression = Pipeline([
    ("poly_features", PolynomialFeatures(degree=10, include_bias=False)),
    ("lin_reg", LinearRegression()),
])
plot_learning_curves(polynomial_regression, X, y)
polynomial_regression = Pipeline([
    ("poly_features", PolynomialFeatures(degree=10, include_bias=False)),
    ("lin_reg", LinearRegression()),
])
plot_learning_curves(polynomial_regression, X, y)
plt.plot_learning_curves(polynomial_regression, X, y)
plt.show()