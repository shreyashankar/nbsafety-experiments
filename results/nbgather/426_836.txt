housing = pd.io.parsers.read_csv('housing.txt', sep='\s+')
corr = housing.corr()
def plotScatter(df, target, cols=3):
    """ Plot scatter plots for each attribute against target attribute
    inputs:
    -------
    * df     - DataFrame of data
    * target - Name of target column
    * cols   - Number of subplot columns for scatter plots
    """
    rows = int(np.ceil(df.shape[-1]/3.0))
    f, axes = plt.subplots(rows, cols)
    for ix, attrib in enumerate(housing.columns):
        if attrib == target:
            continue
        row = ix/cols
        col = np.mod(ix, cols)
        axes[row, col].scatter(df[attrib], df[target], c='gray', s=50)
        axes[row, col].set_xlabel(attrib, fontsize=12)
        axes[row, col].set_ylabel(target, fontsize=12) 
    f.tight_layout()
np.abs(corr.sort(columns=['crime', 'residential']))
def LR_solve(X, y):
    """ Solves a linear regression problem.
    params:
    -------
    * X - Input matrix where each row corresponds to an example.
    * y - Target values
    returns:
    --------
    * w - Vector of fitting coefficients for least squares fit
    notes:
    ------
    * A^*A\hat{x} = A^*b
      \hat{x} = A^* A A^* b
    """
    if len(X.shape) == 2:
        A = np.hstack( (np.ones((X.shape[0],1)), X) )
    else:
        A = np.hstack( (np.ones((X.shape[0],1)), np.expand_dims(X,1)) )
    rtn = np.linalg.lstsq(A, y)
    return rtn[0]
def LR_predict(X, w):
    """ Returns prediction for input data using least squares weights w.
    params:
    -------
    * X - Input matrix of test data
    * w - Weights for least squares fit
    returns:
    --------
    * y - Predictions using LSF coefficients w
    """
    rtn = np.zeros((X.shape[0],))
    if len(X.shape) == 2:
 #       print 'Making prediction using %d weights' % len(w)
        rtn = w[0]
        for i in np.arange(1,len(w)):
            # Weights have extra term compared to data (w0) so there is an offset
            rtn += X[:,i-1]*w[i]
    else:
#    print 'Making prediction using %d weights' % 2
        rtn = w[0] + X[:]*w[1]
    return rtn
def extendX(X):
    """ Expands X to include all linear and degree two polynomials.
    params:
    -------
    X - Matrix of features
    returns:
    expX - Expanded X that includes all linear *and* degree two polynomials
    """
    rows = X.shape[0]
    # w_o + linear terms + quad terms (n*(n+1))/2 
    cols = 1 + X.shape[1] + (X.shape[1]*(X.shape[1]+1))/2
    startExp = 1 + X.shape[1]
    expX = np.ones( (rows, cols) )
    expX[:, 1:X.shape[1]+1] = X
    expCount = -1
    for m in np.arange(X.shape[1]):
        for n in np.arange(m, X.shape[1]):
            expCount = expCount + 1
            expX[:,startExp+expCount] = X[:,m]*X[:,n]
    return expX
def predict(X, w):
    """ Predict class using weights """
    yhat = np.zeros( (X.shape[0],))
    h = sigmoid(np.dot(X, w))
    yhat = np.where(X > 0.5, 1, 0)
    return yhat
def predict(X, w):
    """ Predict class using weights """
    yhat = np.zeros( (X.shape[0],))
    h = sigmoid(np.dot(X, w))
    yhat = np.where(X > 0.5, 1, 0)
    return yhat
def predict(X, w):
    """ Predict class using weights """
    yhat = np.zeros( (X.shape[0],))
    h = sigmoid(np.dot(X, w))
    yhat = np.where(X > 0.5, 1, 0)
    return yhat
def predict(X, w):
    """ Predict class using weights """
    yhat = np.zeros( (X.shape[0],))
    h = sigmoid(np.dot(X, w))
    yhat = np.where(X > 0.5, 1, 0)
    return yhat
def predict(X, w):
    """ Predict class using weights """
    yhat = np.zeros( (X.shape[0],))
    h = sigmoid(np.dot(X, w))
    yhat = np.where(X > 0.5, 1, 0)
    return yhat
def predict(X, w):
    """ Predict class using weights """
    yhat = np.zeros( (X.shape[0],))
    X = np.r_[ np.ones(X.shape[0],), X]
    h = sigmoid(X.dot(w))
    yhat = np.where(X > 0.5, 1, 0)
    return yhat
def predict(X, w):
    """ Predict class using weights """
    yhat = np.zeros( (X.shape[0],))
    X = np.c_[ np.ones(X.shape[0],), X]
    h = sigmoid(X.dot(w))
    yhat = np.where(X > 0.5, 1, 0)
    return yhat
np.array(np.random.randint(12)).reshape(6,2)
np.array(np.random.randint(12))
def predict_class(X, mu, sigma, priors):
    a0 = np.log(priors[0]/priors[1]) - 0.5*(mu[0,:] + mu[1,:]).T*np.linalg.inv(sigma)*(mu[0,:]-mu[1,:])
    a = np.linalg.inv(sigma)*(mu[0,:] - mu[1,:])
    pred = np.zeros((X.shape[0],))
    for row in np.arange(X.shape[0]):
        if (a0 + np.sum( a*X[row,:] )) > 0:
            pred[row] = 1
        else:
            pred[row] = 0
    return pred                                                                           
def predict(X, w):
    """ Predict class using weights """
    yhat = np.zeros( (X.shape[0],))
    X = np.c_[ np.ones(X.shape[0],), X]
    h = sigmoid(X.dot(w))
    yhat = np.where(X > 0.5, 1, 0)
    return yhat
def predict(X, w):
    """ Predict class using weights """
    yhat = np.zeros( (X.shape[0],))
    X = np.c_[ np.ones(X.shape[0],), X]
    h = sigmoid(X.dot(w))
    yhat = np.where(X > 0.5, 1, 0)
    return yhat
def predict(X, w):
    """ Predict class using weights """
    yhat = np.zeros( (X.shape[0],))
    X = np.c_[ np.ones(X.shape[0],), X]
    h = sigmoid(X.dot(w))
    yhat = np.where(X > 0.5, 1, 0)
    return yhat
def predict(X, w):
    """ Predict class using weights """
    yhat = np.zeros( (X.shape[0],))
    X = np.c_[ np.ones(X.shape[0],), X]
    h = sigmoid(X.dot(w))
    yhat = np.where(X > 0.5, 1, 0)
    return yhat
def predict(X, w):
    """ Predict class using weights """
    yhat = np.zeros( (X.shape[0],))
    X = np.c_[ np.ones(X.shape[0],), X]
    h = sigmoid(X.dot(w))
    yhat = np.where(X > 0.5, 1, 0)
    return yhat
def predict(X, w):
    """ Predict class using weights """
    yhat = np.zeros( (X.shape[0],))
    X = np.c_[ np.ones(X.shape[0],), X]
    h = sigmoid(X.dot(w))
    yhat = np.where(X > 0.5, 1, 0)
    return yhat
def predict(X, w):
    """ Predict class using weights """
    yhat = np.zeros( (X.shape[0],))
    X = np.c_[ np.ones(X.shape[0],), X]
    h = sigmoid(X.dot(w))
    yhat = np.where(X > 0.5, 1, 0)
    return yhat
def predict(X, w):
    """ Predict class using weights """
    yhat = np.zeros( (X.shape[0],))
    X = np.c_[ np.ones(X.shape[0],), X]
    h = sigmoid(X.dot(w))
    yhat = np.where(X > 0.5, 1, 0)
    return yhat
def predict(X, w):
    """ Predict class using weights """
    yhat = np.zeros( (X.shape[0],))
    X = np.c_[ np.ones(X.shape[0],), X]
    h = sigmoid(X.dot(w))
    yhat = np.where(X > 0.5, 1, 0)
    return yhat
def predict(X, w):
    """ Predict class using weights """
    yhat = np.zeros( (X.shape[0],))
    X = np.c_[ np.ones(X.shape[0],), X]
    h = sigmoid(X.dot(w))
    yhat = np.where(X > 0.5, 1, 0)
    return yhat
def predict(X, w):
    """ Predict class using weights """
    yhat = np.zeros( (X.shape[0],))
    X = np.c_[ np.ones(X.shape[0],), X]
    h = sigmoid(X.dot(w))
    yhat = np.where(X > 0.5, 1, 0)
    return yhat
def predict(X, w):
    """ Predict class using weights """
    yhat = np.zeros( (X.shape[0],))
    X = np.c_[ np.ones(X.shape[0],), X]
    h = sigmoid(X.dot(w))
    yhat = np.where(X > 0.5, 1, 0)
    return yhat
def predict(X, w):
    """ Predict class using weights """
    yhat = np.zeros( (X.shape[0],))
    h = calc_yhat(X, w)
    yhat = np.where(X > 0.5, 1, 0)
    return yhat
tr_y, tst_y, w = main2_2()
def predict(X, w):
    """ Predict class using weights """
    yhat = np.zeros( (X.shape[0],))
    h = calc_yhat(X, w)
    yhat = np.where(X > 0.5, 1, 0)
    return yhat
tr_y, tst_y, w = main2_2()
def predict(X, w):
    """ Predict class using weights """
    yhat = np.zeros( (X.shape[0],))
    h = calc_yhat(X, w)
    yhat = np.where(X > 0.5, 1, 0)
    return yhat
tr_y, tst_y, w = main2_2()
def predict(X, w):
    """ Predict class using weights """
    yhat = np.zeros( (X.shape[0],))
    h = calc_yhat(X, w)
    yhat = np.where(X > 0.5, 1, 0)
    return yhat
tr_y, tst_y, w = main2_2()
def predict(X, w):
    """ Predict class using weights """
    yhat = np.zeros( (X.shape[0],))
    h = calc_yhat(X, w)
    yhat = np.where(X > 0.5, 1, 0)
    return yhat
tr_y, tst_y, w = main2_2()
def predict(X, w):
    """ Predict class using weights """
    yhat = np.zeros( (X.shape[0],))
    h = calc_yhat(X, w)
    yhat = np.where(X > 0.5, 1, 0)
    return yhat
tr_y, tst_y, w = main2_2()
def predict(X, w):
    """ Predict class using weights """
    yhat = np.zeros( (X.shape[0],))
    h = calc_yhat(X, w)
    yhat = np.where(X > 0.5, 1, 0)
    return yhat
tr_y, tst_y, w = main2_2()
def predict(X, w):
    """ Predict class using weights """
    yhat = np.zeros( (X.shape[0],))
    h = calc_yhat(X, w)
    yhat = np.where(X > 0.5, 1, 0)
    return yhat
tr_y, tst_y, w = main2_2()
def predict(X, w):
    """ Predict class using weights """
    yhat = np.zeros( (X.shape[0],))
    h = calc_yhat(X, w)
    yhat = np.where(X > 0.5, 1, 0)
    return yhat
tr_y, tst_y, w = main2_2()
def predict(X, w):
    """ Predict class using weights """
    yhat = np.zeros( (X.shape[0],))
    h = calc_yhat(X, w)
    yhat = np.where(X > 0.5, 1, 0)
    return yhat
tr_y, tst_y, w, tr_h, te_h = main2_2()
def predict(X, w):
    """ Predict class using weights """
    yhat = np.zeros( (X.shape[0],))
    h = calc_yhat(X, w)
    yhat = np.where(X > 0.5, 1, 0)
    return yhat, h
tr_y, tst_y, w, tr_h, te_h = main2_2()
def predict(X, w):
    """ Predict class using weights """
    yhat = np.zeros( (X.shape[0],))
    h = calc_yhat(X, w)
    yhat = np.where(h > 0.5, 1, 0)
    return yhat, h
def predict(X, w):
    """ Predict class using weights """
    yhat = np.zeros( (X.shape[0],))
    h = calc_yhat(X, w)
    yhat[h > 0.5] = 1
    yhat[h <= 0.5] = 0 
    return yhat, h
np.mean(train_y != train_b)
np.mean(tr_y != train_b)
def main2_2():
    # Load data
    test = np.genfromtxt('./classification_test.txt')
    train = np.genfromtxt('./classification_train.txt')
    train_X = train[:, :-1]
    train_b = train[:, -1]
    test_X = test[:, :-1]
    test_b = test[:, -1]
    # Find optimal weights
    nSamples, nFeatures = train_X.shape
    w = np.ones((nFeatures + 1,))
    w = GLR(train_X, train_b, w, alpha=2, steps=1, annealedLearning=True)
    # Predictions
    train_y, tr_h = predict(train_X, w)
    test_y, te_h = predict(test_X, w)
    #print 'Train_y: ', train_y[:2]
    #print 'Test_y: ', test_y[:2]
    # Test
    train_errors = np.mean(test_y != test_b)
    test_errors = np.mean(train_y != train_b) 
    #print 'Test error rate: ', test_errors
    #print 'Train errors rate: ', train_errors
    #print ''
    return train_y, test_y, w, tr_h, te_h
def predict(X, w):
    """ Predict class using weights """
    yhat = np.zeros( (X.shape[0],))
    h = calc_yhat(X, w)
    yhat[h > 0.5] = 1
    yhat[h <= 0.5] = 0 
    return yhat, h
def main2_2():
    # Load data
    test = np.genfromtxt('./classification_test.txt')
    train = np.genfromtxt('./classification_train.txt')
    train_X = train[:, :-1]
    train_b = train[:, -1]
    test_X = test[:, :-1]
    test_b = test[:, -1]
    # Find optimal weights
    nSamples, nFeatures = train_X.shape
    w = np.ones((nFeatures + 1,))
    w = GLR(train_X, train_b, w, alpha=2, steps=1, annealedLearning=True)
    # Predictions
    train_y, tr_h = predict(train_X, w)
    test_y, te_h = predict(test_X, w)
    #print 'Train_y: ', train_y[:2]
    #print 'Test_y: ', test_y[:2]
    # Test
    train_errors = np.mean(test_y != test_b)
    test_errors = np.mean(train_y != train_b) 
    #print 'Test error rate: ', test_errors
    #print 'Train errors rate: ', train_errors
    #print ''
    return train_y, test_y, w, tr_h, te_h
def predict(X, w):
    """ Predict class using weights """
    yhat = np.zeros( (X.shape[0],))
    h = calc_yhat(X, w)
    yhat[h > 0.5] = 1
    yhat[h <= 0.5] = 0 
    return yhat, h
np.mean(tr_y != train_b)
def predict(X, w):
    """ Predict class using weights """
    yhat = np.zeros( (X.shape[0],))
    h = calc_yhat(X, w)
    yhat[h > 0.5] = 1
    yhat[h <= 0.5] = 0 
    return yhat, h
def predict(X, w):
    """ Predict class using weights """
    yhat = np.zeros( (X.shape[0],))
    h = calc_yhat(X, w)
    yhat[h > 0.5] = 1
    yhat[h <= 0.5] = 0 
    return yhat, h
def main2_2_2():
    # Load data
    test = np.genfromtxt('./classification_test.txt')
    train = np.genfromtxt('./classification_train.txt')
    train_X = train[:, :-1]
    train_b = train[:, -1]
    test_X = test[:, :-1]
    test_b = test[:, -1]
    # Find optimal weights
    nSamples, nFeatures = train_X.shape
    w = np.ones((nFeatures + 1,))
    steps = 500
    numIter = steps/50
    test_errors = np.zeros( (numIter,))
    train_errors = np.zeros( (numIter,))
    for i in np.arange(steps/50):
        w = GLR(train_X, train_b, w, alpha=2, steps=steps, annealedLearning=True)
        # Predictions
        train_y, tr_h = predict(train_X, w)
        test_y, te_h = predict(test_X, w)
        #print 'Train_y: ', train_y[:2]
        #print 'Test_y: ', test_y[:2]
        # Test
        train_errors[i] = np.mean(test_y != test_b)
        test_errors[i] = np.mean(train_y != train_b) 
        #print 'Test error rate: ', test_errors[i]
        #print 'Train errors rate: ', train_errors[i]
        #print 'weights: ', w
    # Plot
    fig, ax = plt.subplots()
    ax.plot(np.arange(numIter), test_errors, 'r', marker='o', label='Test')
    ax.plot(np.arange(numIter), train_errors, 'b', marker='x', label='Training')
    plt.title('Classification error %')
    plt.legend()
    return train_y, test_y, w, tr_h, te_h
def main2_2_2():
    # Load data
    test = np.genfromtxt('./classification_test.txt')
    train = np.genfromtxt('./classification_train.txt')
    train_X = train[:, :-1]
    train_b = train[:, -1]
    test_X = test[:, :-1]
    test_b = test[:, -1]
    # Find optimal weights
    nSamples, nFeatures = train_X.shape
    w = np.ones((nFeatures + 1,))
    steps = 500
    numIter = steps/50
    test_errors = np.zeros( (numIter,))
    train_errors = np.zeros( (numIter,))
    for i in np.arange(steps/50):
        w = GLR(train_X, train_b, w, alpha=2, steps=steps, annealedLearning=True)
        # Predictions
        train_y, tr_h = predict(train_X, w)
        test_y, te_h = predict(test_X, w)
        #print 'Train_y: ', train_y[:2]
        #print 'Test_y: ', test_y[:2]
        # Test
        train_errors[i] = np.mean(test_y != test_b)
        test_errors[i] = np.mean(train_y != train_b) 
        #print 'Test error rate: ', test_errors[i]
        #print 'Train errors rate: ', train_errors[i]
        #print 'weights: ', w
    # Plot
    fig, ax = plt.subplots()
    ax.plot(np.arange(numIter), test_errors, 'r', marker='o', label='Test')
    ax.plot(np.arange(numIter), train_errors, 'b', marker='x', label='Training')
    plt.title('Classification error %')
    plt.legend()
    return train_y, test_y, w, tr_h, te_h
def main2_2_2():
    # Load data
    test = np.genfromtxt('./classification_test.txt')
    train = np.genfromtxt('./classification_train.txt')
    train_X = train[:, :-1]
    train_b = train[:, -1]
    test_X = test[:, :-1]
    test_b = test[:, -1]
    # Find optimal weights
    nSamples, nFeatures = train_X.shape
    w = np.ones((nFeatures + 1,))
    steps = 500
    numIter = steps/50
    test_errors = np.zeros( (numIter,))
    train_errors = np.zeros( (numIter,))
    for i in np.arange(steps/50):
        w = GLR(train_X, train_b, w, alpha=2, steps=steps, annealedLearning=True)
        # Predictions
        train_y, tr_h = predict(train_X, w)
        test_y, te_h = predict(test_X, w)
        #print 'Train_y: ', train_y[:2]
        #print 'Test_y: ', test_y[:2]
        # Test
        train_errors[i] = np.mean(test_y != test_b)
        test_errors[i] = np.mean(train_y != train_b) 
        #print 'Test error rate: ', test_errors[i]
        #print 'Train errors rate: ', train_errors[i]
        #print 'weights: ', w
    # Plot
    fig, ax = plt.subplots()
    ax.plot([50*x for x in range(1,numIter+1)], test_errors, 'r', marker='o', label='Test')
    ax.plot([50*x for x in range(1,numIter+1)], train_errors, 'b', marker='x', label='Training')
    plt.title('Classification error %')
    plt.legend()
    return train_y, test_y, w, tr_h, te_h
def calc_ccm(X, y):
    """ Calculates class conditional mean 
    inputs:
    -------
    * X - Data
    * y - labels
    returns:
    --------
    * mu - MLE of means of class conditional densities
    """
    classes = np.unique(y)
    nClasses = len(classes)
    mu = np.zeros((nClasses,X.shape[1]))
    for i, cls in enumerate(classes):
        mu[i] = X[np.where(y==cls)[0],:].mean(axis=0)
    return mu
def calc_cov(X,y, mu):
    """ Calculate shared covariance matrix"""
    classes = np.unique(y)
    nClasses = len(classes)
    sigma = np.zeros((nClasses,nClasses))
    for i, cls in enumerate(classes):
        x = X[np.where(y==cls)[0], :]
        sigma += np.dot((x - mu[i,:]).T,(x - mu[i,:]) )
    sigma /= (X.shape[0] - nClasses)
    return sigma
def calc_ccm(X, y):
    """ Calculates class conditional mean 
    inputs:
    -------
    * X - Data
    * y - labels
    returns:
    --------
    * mu - MLE of means of class conditional densities
    """
    classes = np.unique(y)
    nClasses = len(classes)
    mu = np.zeros((nClasses,X.shape[1]))
    for i, cls in enumerate(classes):
        mu[i] = X[np.where(y==cls)[0],:].mean(axis=0)
    return mu
def calc_cov(X,y, mu):
    """ Calculate shared covariance matrix"""
    classes = np.unique(y)
    nClasses = len(classes)
    sigma = np.zeros((nClasses,nClasses))
    for i, cls in enumerate(classes):
        x = X[np.where(y==cls)[0], :]
        sigma += np.dot((x - mu[i,:]).T,(x - mu[i,:]) )
    sigma /= (X.shape[0] - nClasses)
    return sigma
def max_likelihood(X, y):
    """ Calculates class conditional estimates.
    params:
    -------
    * X - Data
    * y - labels
    returns:
    --------
    * thetas - Estimates of model parameters
    """
    mu = calc_ccm(X, y)
    sigma = calc_cov(X, y, mu)
    return mu, sigma
def calc_priors(X, y):
    classes = np.unique(y)
    nClasses = len(classes)
    priors = np.zeros((nClasses,))
    for i, cls in enumerate(classes):
        priors[i] = len(np.where(y==cls)[0])/float(X.shape[0])
    return priors
def calc_priors(X, y):
    classes = np.unique(y)
    nClasses = len(classes)
    priors = np.zeros((nClasses,))
    for i, cls in enumerate(classes):
        priors[i] = len(np.where(y==cls)[0])/float(X.shape[0])
    return priors
predict_class(test_X, m, s, np.array([0.5,0.5]))
def main4():   
    # Load the data
    test = np.genfromtxt('./classification_test.txt')
    train = np.genfromtxt('./classification_train.txt')
    test_X = test[:,:-1]
    train_X = train[:, :-1]    
    train_b = train[:, -1]
    test_b = test[:,-1]
    # Calc stats
    train_mu, train_sigma = max_likelihood(train_X, train_b)
    train_priors = calc_priors(train_X, train_b)
    test_mu, test_sigma = max_likelihood(test_X, test_b)
    test_priors = calc_priors(test_X, test_b)
    # Make predictions
    train_yhat = predict_class(train_X, train_mu, train_sigma, train_priors)
    test_yhat = predict_class(test_X, test_mu, test_sigma, test_priors)
    # Print errors
    'Training classification error rate: %f' % calc_errors(train_yhat, train_b)
    'Test classification error rate: %f' % calc_errors(test_yhat, test_b) 
def main4():   
    # Load the data
    test = np.genfromtxt('./classification_test.txt')
    train = np.genfromtxt('./classification_train.txt')
    test_X = test[:,:-1]
    train_X = train[:, :-1]    
    train_b = train[:, -1]
    test_b = test[:,-1]
    # Calc stats
    train_mu, train_sigma = max_likelihood(train_X, train_b)
    train_priors = calc_priors(train_X, train_b)
    test_mu, test_sigma = max_likelihood(test_X, test_b)
    test_priors = calc_priors(test_X, test_b)
    # Make predictions
    train_yhat = predict_class(train_X, train_mu, train_sigma, train_priors)
    test_yhat = predict_class(test_X, test_mu, test_sigma, test_priors)
    # Print errors
    'Training classification error rate: %f' % calc_errors(train_yhat, train_b)
    'Test classification error rate: %f' % calc_errors(test_yhat, test_b) 
def main4():   
    # Load the data
    test = np.genfromtxt('./classification_test.txt')
    train = np.genfromtxt('./classification_train.txt')
    test_X = test[:,:-1]
    train_X = train[:, :-1]    
    train_b = train[:, -1]
    test_b = test[:,-1]
    # Calc stats
    train_mu, train_sigma = max_likelihood(train_X, train_b)
    train_priors = calc_priors(train_X, train_b)
    test_mu, test_sigma = max_likelihood(test_X, test_b)
    test_priors = calc_priors(test_X, test_b)
    # Make predictions
    train_yhat = predict_class(train_X, train_mu, train_sigma, train_priors)
    test_yhat = predict_class(test_X, test_mu, test_sigma, test_priors)
    # Print errors
    'Training classification error rate: %f' % calc_errors(train_yhat, train_b)
    'Test classification error rate: %f' % calc_errors(test_yhat, test_b) 
main4()